{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、配置类（BertConfig）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../models/chinese-bert-wwm-ext/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "  \"architectures\": [\n",
    "    \"BertForMaskedLM\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"directionality\": \"bidi\",\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.0002,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"model_type\": \"bert\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"output_past\": True,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"pooler_fc_size\": 768,\n",
    "  \"pooler_num_attention_heads\": 12,\n",
    "  \"pooler_num_fc_layers\": 3,\n",
    "  \"pooler_size_per_head\": 128,\n",
    "  \"pooler_type\": \"first_token_transform\",\n",
    "  \"type_vocab_size\": 2,\n",
    "  \"vocab_size\": 21128\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size,\n",
    "        hidden_size=768,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act='gelu',\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02\n",
    "    ):\n",
    "        '''\n",
    "        vocab_size：词表大小\n",
    "        hidden_size：隐藏层神经元数\n",
    "        num_hidden_layers：Transformer encoder 中的隐藏层数\n",
    "        *num_attention_heads：*multi-head attention 的 head 数\n",
    "        intermediate_size：encoder 的“中间”隐层神经元数（例如 feed-forward layer）\n",
    "        hidden_act：隐藏层激活函数\n",
    "        hidden_dropout_prob：隐层 dropout 率\n",
    "        attention_probs_dropout_prob：注意力部分的 dropout\n",
    "        max_position_embeddings：最大位置编码\n",
    "        type_vocab_size：token_type_ids 的词典大小\n",
    "        initializer_range：truncated_normal_initializer 初始化方法的 stdev\n",
    "        '''\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "    \n",
    "    # 从字典获得参数\n",
    "    @classmethod    \n",
    "    def from_json_dict(cls, json_object):\n",
    "        config = BertConfig(vocab_size=None)\n",
    "        for (key, value) in json_object.items():\n",
    "            # 添加config的参数\n",
    "            config.__dict__[key] = value\n",
    "        return config\n",
    "    \n",
    "    # 从json文件获得参数\n",
    "    @classmethod\n",
    "    def from_json_file(cls, json_file):\n",
    "        with open(json_file, 'r', encoding='utf8') as f:\n",
    "            return cls.from_json_dict(json.load(f))\n",
    "        \n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "    \n",
    "    def to_json_string(self):\n",
    "        # indent: 格式缩进\n",
    "        return json.dumps(self.to_dict(), indent=2) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、获取词向量（Embedding_lookup）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size, \n",
    "        max_sen_len=512,\n",
    "        seg_type=2,\n",
    "        embedding_size=128, \n",
    "        initializer_range=0.02,\n",
    "        padding_idx=0,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, \n",
    "            embedding_dim =embedding_size,\n",
    "            padding_idx=padding_idx)\n",
    "        \n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            num_embeddings=max_sen_len, \n",
    "            embedding_dim =embedding_size,)\n",
    "        \n",
    "        self.seg_embedding = nn.Embedding(\n",
    "            num_embeddings=seg_type, \n",
    "            embedding_dim =embedding_size,)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def process_token(self, input_ids, seg_ids):\n",
    "        assert input_ids.ndim == seg_ids.ndim \n",
    "        assert input_ids.ndim == 2\n",
    "        \n",
    "        # token_embed : [batch_size, sen, embedding_size]\n",
    "        token_embed = self.token_embedding(input_ids)\n",
    "        \n",
    "        # pos_embed : [1,sen, embedding_size]\n",
    "        # 由于pos_embed跟句子中token的位置有关，因此使用切片取出pos_embedding\n",
    "        # 但此时embedding只有两个维度:[sen, embedding]，因此需要在第0维扩展\n",
    "        # 方便后面广播相加\n",
    "        pos_embed = self.pos_embedding.weight[:input_ids.shape[1]].unsqueeze(0)\n",
    "\n",
    "        # seg_embed : [batch_size, sen, embedding_size]\n",
    "        # 根据传入的seg_ids进行嵌入，一般seg_ids只有两个值\n",
    "        seg_embed = self.seg_embedding(seg_ids)\n",
    "        print(seg_embed.shape)\n",
    "        return self.dropout(token_embed + pos_embed + seg_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、Transformer block(Encoder部分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multihead_Attention(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "        sen_len = q.shape[2]\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "        # scores : [batch_size, heads, sen_len, sen_len] -> [2, 4, 5, 5]\n",
    "\n",
    "        # mask掉那些为了padding长度增加的token，让其通过softmax计算后为0\n",
    "        if mask is not None:\n",
    "            # mask初始size : [batch_size, sen_len]\n",
    "            # 将其填充为 [batch_size, 1, sen_len, sen_len]\n",
    "            # 例：mask = tensor([[1., 1., 1., 0., 0.],\n",
    "            #                    [1., 1., 1., 0., 0.]])      -> [2,5]\n",
    "            # 经google的bert源码测试后得出\n",
    "            # 填充后为    tensor([[[[1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.]]],\n",
    "    #                             [[[1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.],\n",
    "    #                               [1., 1., 1., 0., 0.]]]])  ->[2,1,5,5]\n",
    "            mask = mask.unsqueeze(1).repeat(1, sen_len, 1).unsqueeze(1)\n",
    "    #         mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)  \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)   \n",
    "    output = torch.matmul(scores, v)\n",
    "    # output : [batch_size, heads, sen_len, d_k]\n",
    "    return output\n",
    "    \n",
    "    # q, k, v 分别传入，以便cross-attention传参\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # x : [batch_size, sen_len, d_model]\n",
    "        bs = x.shape[0]\n",
    "        # 将sen_len的维度与heads的维度互换，进行多头注意力的计算\n",
    "        # 转换后的size : [batch_size, heads, sen_len, d_model]\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k).transpose(1,2)\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k).transpose(1,2)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k).transpose(1,2)\n",
    "        \n",
    "        attentioned = self.attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        concat = attentioned.transpose(1,2).contiguous().view(bs, -1, self.model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）Layer Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）Feed Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand([2,4,5,10])\n",
    "k = torch.rand([2,4,5,10])\n",
    "v = torch.rand([2,4,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.cat((torch.ones([2,3]), torch.zeros([2,2])), -1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2944, 0.3113, 0.3942, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([5.6534e-01, 6.2107e-01, 8.5721e-01, -1e9, -1e9])\n",
    "F.softmax(test, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-5fb83e359bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-171-7f1ff3bc1adb>\u001b[0m in \u001b[0;36mattention\u001b[1;34m(q, k, v, d_k, mask, dropout)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#         mask = mask.unsqueeze(1).repeat(1, sen_len, 1).unsqueeze(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "s = attention(q,k,v,d_k,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mul-torch",
   "language": "python",
   "name": "mul-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
